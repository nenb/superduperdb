"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[9888],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>k});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=a.createContext({}),s=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},d=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),m=s(n),c=r,k=m["".concat(p,".").concat(c)]||m[c]||u[c]||o;return n?a.createElement(k,l(l({ref:t},d),{},{components:n})):a.createElement(k,l({ref:t},d))}));function k(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,l=new Array(o);l[0]=c;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i[m]="string"==typeof e?e:r,l[1]=i;for(var s=2;s<o;s++)l[s]=n[s];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},10518:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>s});var a=n(87462),r=(n(67294),n(3905));const o={sidebar_position:3},l="Models",i={unversionedId:"docs/usage/models",id:"docs/usage/models",title:"Models",description:"The SuperDuperDB Model wrapper is an extension of standard Python-AI-ecosystem models.",source:"@site/content/docs/usage/models.md",sourceDirName:"docs/usage",slug:"/docs/usage/models",permalink:"/docs/docs/usage/models",draft:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/tree/main/docs/content/docs/usage/models.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Encoders",permalink:"/docs/docs/usage/encoders"},next:{title:"Queries",permalink:"/docs/docs/usage/queries"}},p={},s=[{value:"Supported frameworks",id:"supported-frameworks",level:2},{value:"Vanilla Usage",id:"vanilla-usage",level:2},{value:"PyTorch",id:"pytorch",level:2},{value:"Transformers",id:"transformers",level:2},{value:"Sklearn",id:"sklearn",level:2},{value:"OpenAI",id:"openai",level:2},{value:"Quickly porting models to SuperDuperDB",id:"quickly-porting-models-to-superduperdb",level:2},{value:"Applying models to data with <code>.predict</code>",id:"applying-models-to-data-with-predict",level:2},{value:"Training models on data with <code>.fit</code>",id:"training-models-on-data-with-fit",level:2},{value:"Model design",id:"model-design",level:2},{value:"Preprocessing",id:"preprocessing",level:3},{value:"Postprocessing",id:"postprocessing",level:3},{value:"Encoding",id:"encoding",level:3},{value:"Daemonizing models with listeners",id:"daemonizing-models-with-listeners",level:2}],d={toc:s},m="wrapper";function u(e){let{components:t,...n}=e;return(0,r.kt)(m,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"models"},"Models"),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"The SuperDuperDB ",(0,r.kt)("inlineCode",{parentName:"p"},"Model")," wrapper is an extension of standard Python-AI-ecosystem models.\n",(0,r.kt)("inlineCode",{parentName:"p"},"Model")," adds preprocessing, postprocessing, and communication with the ",(0,r.kt)("inlineCode",{parentName:"p"},"DB"),"\nto the standard toolkit."),(0,r.kt)("p",{parentName:"admonition"},"In order to use an AI model with SuperDuperDB, it's necessary to wrap it with\na class inheriting from ",(0,r.kt)("inlineCode",{parentName:"p"},"Model"))),(0,r.kt)("p",null,"In SuperDuperDB, the primary mode to integrating a new AI model, framework or API provider\nis via the ",(0,r.kt)("inlineCode",{parentName:"p"},"Model")," abstraction. This maybe thought of in the following way:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"A wrapper around AI frameworks facilitating use of models with the database."),(0,r.kt)("li",{parentName:"ul"},"A self contained unit of functionality handling all communication with the database."),(0,r.kt)("li",{parentName:"ul"},"A unifying abstraction bringing all AI frameworks onto a single playing field."),(0,r.kt)("li",{parentName:"ul"},"A trainable, parametrizable extension of UDFs from traditional databases.")),(0,r.kt)("p",null,"The uniformity of the abstraction is inspired by the Sklearn ",(0,r.kt)("inlineCode",{parentName:"p"},".fit"),", ",(0,r.kt)("inlineCode",{parentName:"p"},".predict")," paradigm,\nbut with additional features which are required in order to allow the models to read and\nwrite to the database. We extend this paradigm to frameworks, which have taken their\nown path in API design, bringing all frameworks into a single world of terminology and\nfunctionality."),(0,r.kt)("h2",{id:"supported-frameworks"},"Supported frameworks"),(0,r.kt)("p",null,"The following frameworks are supported natively by SuperDuperDB:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://scikit-learn.org/stable/"},(0,r.kt)("inlineCode",{parentName:"a"},"sklearn"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pytorch.org/"},(0,r.kt)("inlineCode",{parentName:"a"},"torch"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://huggingface.co/docs/transformers/index"},(0,r.kt)("inlineCode",{parentName:"a"},"transformers"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/api-reference?lang=python"},(0,r.kt)("inlineCode",{parentName:"a"},"openai")))),(0,r.kt)("p",null,"The base class is ",(0,r.kt)("inlineCode",{parentName:"p"},"superduperdb.container.model.Model"),".\nThe key classes for frameworks are located in ",(0,r.kt)("inlineCode",{parentName:"p"},"superduperdb.ext.<framework>.<Framework>Model"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"superduperdb.ext.sklearn.SklearnModel.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"superduperdb.ext.torch.TorchModel.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"superduperdb.ext.transformers.TransformersModel.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"superduperdb.ext.openai.OpenAIModel."))),(0,r.kt)("p",null,"The wrappers from each framework include parameters fom the ",(0,r.kt)("inlineCode",{parentName:"p"},"Model")," base class:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.core.model import Model\n\nm = Model(\n    object=<model>,    # object from one of the AI frameworks\n    preprocess=<preprocess>,    # callable\n    postprocess=<postprocess>,    # callable\n    encoder=<encoder>,    # `Encoder` instance\n)\n")),(0,r.kt)("p",null,"See ",(0,r.kt)("a",{parentName:"p",href:"#model-design"},"below")," for an explanation of each of these parameters.\nHere are examples of each of these parameters in several frameworks and applications:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Application"),(0,r.kt)("th",{parentName:"tr",align:null},"Task"),(0,r.kt)("th",{parentName:"tr",align:null},"Framework(s)"),(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"th"},"object")),(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"th"},"preprocess")),(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"th"},"postprocess")),(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"th"},"encoder")))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Vision"),(0,r.kt)("td",{parentName:"tr",align:null},"Classification"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"torch")),(0,r.kt)("td",{parentName:"tr",align:null},"CNN"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"torchvision.transforms")),(0,r.kt)("td",{parentName:"tr",align:null},"Top-K estimate"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Generative"),(0,r.kt)("td",{parentName:"tr",align:null},"Image generation"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"torch")),(0,r.kt)("td",{parentName:"tr",align:null},"GAN"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"pillow"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"NLP"),(0,r.kt)("td",{parentName:"tr",align:null},"LLM"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"transformers")),(0,r.kt)("td",{parentName:"tr",align:null},"Transformer"),(0,r.kt)("td",{parentName:"tr",align:null},"Tokenizer"),(0,r.kt)("td",{parentName:"tr",align:null},"Sampling"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Risk"),(0,r.kt)("td",{parentName:"tr",align:null},"Fraud detection"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"sklearn")),(0,r.kt)("td",{parentName:"tr",align:null},"Estimator"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Search"),(0,r.kt)("td",{parentName:"tr",align:null},"Vector Search"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"openai")),(0,r.kt)("td",{parentName:"tr",align:null},"OpenAI Embedding"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"None"))))),(0,r.kt)("h2",{id:"vanilla-usage"},"Vanilla Usage"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Model")," class supports models which are not natively integrated with SuperDuperDB\nfor inference purposes.\nHere is, for instance, how to wrap a ",(0,r.kt)("inlineCode",{parentName:"p"},"sentence_transformers")," model with the ",(0,r.kt)("inlineCode",{parentName:"p"},"Model"),"\nabstraction:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import sentence_transformers\nfrom superduperdb.container.model import Model\nfrom superduperdb.ext.numpy.array import array\n\nmodel = Model(\n    identifier='all-MiniLM-L6-v2',\n    object=sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2'),\n    encoder=array('float32', shape=(384,)),\n    predict_method='encode',\n    batch_predict=True,\n)\n")),(0,r.kt)("h2",{id:"pytorch"},"PyTorch"),(0,r.kt)("p",null,"PyTorch is a flexible framework which allows users\nto define arbitrary logic in the forward pass, and use backpropagation\ntraining to calibrate models on the data."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.ext.torch import TorchModel\nm = TorchModel(\n    '<model-id>',\n    object=MyTorchModule,    # any module programmable in `torch`\n    preprocess=my_preproces_function,     # any callable\n    postprocess=my_postprocess_function,      # any callable\n    encoder=my_encoder                      # any `Encoder` instance\n)\n")),(0,r.kt)("h2",{id:"transformers"},"Transformers"),(0,r.kt)("p",null,"Transformers provides a large compendium of pre-trained and pre-defined architectures and pipelines. Their ",(0,r.kt)("inlineCode",{parentName:"p"},"transformers.Pipeline")," abstraction fits well with the ",(0,r.kt)("inlineCode",{parentName:"p"},"Model")," framework:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.ext.transformers import TransformersModel\nm = TransformersModel(\n    '<model-id>',\n    object=my_pipeline,    # a `transformers` pipeline \n    preprocess=my_preprocess_function,     # tokenizer, processor or similar\n    postprocess=my_postprocess_function,      # a decoding function\n    encoder=my_encoder                      # any `Encoder` instance\n)\n")),(0,r.kt)("h2",{id:"sklearn"},"Sklearn"),(0,r.kt)("p",null,"Sklearn provides a large library of classical estimators and non-deep learning machine learning algorithms. These algorithms mostly work directly with numerical data:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.ext.sklearn import SklearnModel\n\nm = SklearnModel(\n    '<model-id>',\n    object=<estimator>,    # `sklearn.base.BaseEstimator` or `sklearn.pipeline.Pipeline`\n    preprocess=<preprocess>,    # callable\n    postprocess=<postprocess>,    # callable\n    encoder=<encoder>,    # `Encoder` instance\n)\n")),(0,r.kt)("h2",{id:"openai"},"OpenAI"),(0,r.kt)("p",null,"Since OpenAI consists of calls to an external API, it's model definitions are slightly different:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.ext.openai import OpenAIEmbedding, OpenAIChatCompletion\n\nm1 = OpenAIEmbedding(model='<model-id-1>')\nm2 = OpenAIChatCompletion(model='<model-id-2>')\n")),(0,r.kt)("h2",{id:"quickly-porting-models-to-superduperdb"},"Quickly porting models to SuperDuperDB"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"superduper(model)")," provides a shortcut to importing the model class directly:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb import superduper\nfrom sklearn.svm import SVM\nfrom torch.nn import Linear\nfrom transformers import pipeline\n\n@superduper\ndef my_custom_function(x):\n    return (x + 2) ** 2\n\nsvm = superduper(SVM())\nlinear = superduper(Linear(10, 20))\npipeline = superduper(pipeline...)\n")),(0,r.kt)("h2",{id:"applying-models-to-data-with-predict"},"Applying models to data with ",(0,r.kt)("inlineCode",{parentName:"h2"},".predict")),(0,r.kt)("p",null,"All of the models which we created in the previous step are now ready to be applied to the database:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.db.mongodb.query import Collection\ncoll = Collection('my_data')\nsvm.predict(X='x', db=db, select=coll.find())\n# Wait a bit\ndb.execute(coll.find_one())\nDocument({\n    \"_id\": ObjectId('64b6ba93f8af205501ca7748'),\n    'x': Encodable(x=torch.tensor([...])),\n    '_outputs': {'x': {'svm': 1}}\n})\n")),(0,r.kt)("p",null,"A similar result may be obtained by replaced the ",(0,r.kt)("inlineCode",{parentName:"p"},"svm")," by any of the other models above."),(0,r.kt)("h2",{id:"training-models-on-data-with-fit"},"Training models on data with ",(0,r.kt)("inlineCode",{parentName:"h2"},".fit")),(0,r.kt)("p",null,"Using the same analogy to ",(0,r.kt)("inlineCode",{parentName:"p"},"sklearn"),' above, SuperDuperDB supports "in-database" training of models:'),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"svm.fit(\n    X='x', y='y', db=db, select=coll.find({'_fold': 'train'})\n)\n# Lots of output corresponding to training here\n")),(0,r.kt)("h2",{id:"model-design"},"Model design"),(0,r.kt)("p",null,"Models in SuperDuperDB differ from models in the standard AI frameworks, by\nincluding several additional aspects:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#preprocessing"},"preprocessing")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#postprocessing"},"postprocessing")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#encoding"},"output encoding"))),(0,r.kt)("h3",{id:"preprocessing"},"Preprocessing"),(0,r.kt)("p",null,"All models in SuperDuperDB include the keyword argument ",(0,r.kt)("inlineCode",{parentName:"p"},"preprocess"),". The exact meaning of this varies from framework to framework, however in general:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-{important}"},"`Model.preprocess` is a function which takes an individual data-point from the database, \nand prepares it for processing by the AI framework model\n")),(0,r.kt)("p",null,"For example:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"In PyTorch (",(0,r.kt)("inlineCode",{parentName:"li"},"torch"),") computer vision models, a preprocessing function might:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Crop the image"),(0,r.kt)("li",{parentName:"ul"},"Normalize the pixel values by precomputed constants"),(0,r.kt)("li",{parentName:"ul"},"Resize the image"),(0,r.kt)("li",{parentName:"ul"},"Convert the image to a tensor"))),(0,r.kt)("li",{parentName:"ul"},"In Hugging Face ",(0,r.kt)("inlineCode",{parentName:"li"},"transformers"),", and NLP model will:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Tokenize a sentence into word-pieces"),(0,r.kt)("li",{parentName:"ul"},"Convert each word piece into a numerical ID"),(0,r.kt)("li",{parentName:"ul"},"Truncate and pad the IDs"),(0,r.kt)("li",{parentName:"ul"},"Compute a mask"))),(0,r.kt)("li",{parentName:"ul"},"In Scikit-Learn, estimators operate purely at the numerical level",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Preprocessing may be added exactly as for PyTorch"),(0,r.kt)("li",{parentName:"ul"},"Alternatively users may use a ",(0,r.kt)("inlineCode",{parentName:"li"},"sklearn.pipeline.Pipeline")," explicitly")))),(0,r.kt)("h3",{id:"postprocessing"},"Postprocessing"),(0,r.kt)("p",null,"All models in SuperDuperDB include the keyword argument ",(0,r.kt)("inlineCode",{parentName:"p"},"postprocess"),". The goal here\nis to take the numerical estimates of a model, and convert these to a form to\nbe used by database users. Examples are:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Converting a softmax over a dictionary in NLP to point estimates and human-readable strings"),(0,r.kt)("li",{parentName:"ul"},"Converting a generated image-tensor into JPG or PNG format"),(0,r.kt)("li",{parentName:"ul"},"Performing additional inference logic, such as beam-search in neural translation")),(0,r.kt)("h3",{id:"encoding"},"Encoding"),(0,r.kt)("p",null,"The aim of postprocessing is to provide outputs in a operationally useful\nform. However, often this form isn't directly amenable to insertion in the ",(0,r.kt)("inlineCode",{parentName:"p"},"DB"),".\nDatastores don't typically support images or tensors natively. Consequently\neach model takes the keyword ",(0,r.kt)("inlineCode",{parentName:"p"},"encoder"),", allowing users to specify exactly\nhow outputs are stored in the database as ",(0,r.kt)("inlineCode",{parentName:"p"},"bytes"),", if not supported natively\nby the database. Read more ",(0,r.kt)("a",{parentName:"p",href:"encoders"},"here"),"."),(0,r.kt)("h2",{id:"daemonizing-models-with-listeners"},"Daemonizing models with listeners"),(0,r.kt)("p",null,"Models can be configured so that, when new data is inserted through SuperDuperDB database,\nthen the models spring into action, processing this new data, and repopulating outputs back\ninto the database."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"model.predict(X='input_col', db=db, select=coll.find(), listen=True)\n")),(0,r.kt)("p",null,"An equivalent syntax is the following:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.container.listener import Listener\ndb.add(\n   Listener(\n       model=model,\n       select=coll.find(),\n       key='input_col',\n   )\n)\n")),(0,r.kt)("p",null,"After setting up a ",(0,r.kt)("inlineCode",{parentName:"p"},"Listener"),", whenever data is inserted or updated, jobs are created\nwhich save the outputs of the model in the ",(0,r.kt)("inlineCode",{parentName:"p"},'"_outputs"')," field."),(0,r.kt)("p",null,"A ",(0,r.kt)("inlineCode",{parentName:"p"},"Listener")," may also be configured in ",(0,r.kt)("a",{parentName:"p",href:"/docs/category/cluster"},"cluster mode"),", to listen for changes coming in from any sources - i.e. changes are not just detected through the SuperDuperDB system.\nRead more about that ",(0,r.kt)("a",{parentName:"p",href:"/docs/docs/cluster/change_data_capture"},"here"),"."))}u.isMDXComponent=!0}}]);